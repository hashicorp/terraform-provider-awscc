
---
page_title: "awscc_glue_crawler Resource - terraform-provider-awscc"
subcategory: ""
description: |-
  Resource Type definition for AWS::Glue::Crawler
---

# awscc_glue_crawler (Resource)

Resource Type definition for AWS::Glue::Crawler

## Example Usage

### AWS Glue Crawler with S3 Target

Creates an AWS Glue crawler configuration that scans S3 data with appropriate IAM roles and policies, implementing schema change logging and selective recrawl behavior for new folders.

~> This example is generated by LLM using Amazon Bedrock and validated using terraform validate, apply and destroy. While we strive for accuracy and quality, please note that the information provided may not be entirely error-free or up-to-date. We recommend independently verifying the content.

```terraform
# Get current AWS account ID
data "aws_caller_identity" "current" {}

# S3 bucket for the crawler target
resource "aws_s3_bucket" "crawler_target" {
  bucket = "glue-crawler-example-${data.aws_caller_identity.current.account_id}"
}

# IAM role for the Glue crawler
resource "aws_iam_role" "crawler_role" {
  name = "glue-crawler-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = "sts:AssumeRole"
        Effect = "Allow"
        Principal = {
          Service = "glue.amazonaws.com"
        }
      }
    ]
  })

  tags = {
    "Modified By" = "AWSCC"
  }
}

# Policy to allow Glue to access the S3 bucket
resource "aws_iam_policy" "crawler_s3_policy" {
  name = "glue-crawler-s3-policy"

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow"
        Action = [
          "s3:GetObject",
          "s3:PutObject",
          "s3:DeleteObject"
        ]
        Resource = [
          "${aws_s3_bucket.crawler_target.arn}/*"
        ]
      },
      {
        Effect = "Allow"
        Action = [
          "s3:ListBucket"
        ]
        Resource = [
          aws_s3_bucket.crawler_target.arn
        ]
      }
    ]
  })

  tags = {
    "Modified By" = "AWSCC"
  }
}

# Attach the AWS Glue service role policy
resource "aws_iam_role_policy_attachment" "crawler_service_policy" {
  role       = aws_iam_role.crawler_role.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole"
}

# Attach the S3 bucket policy to the role
resource "aws_iam_role_policy_attachment" "crawler_policy_attachment" {
  role       = aws_iam_role.crawler_role.name
  policy_arn = aws_iam_policy.crawler_s3_policy.arn
}

# Glue crawler
resource "awscc_glue_crawler" "example" {
  name          = "example-crawler"
  role          = aws_iam_role.crawler_role.arn
  database_name = "example_database"
  description   = "Example Glue crawler that crawls S3 data"

  targets = {
    s3_targets = [{
      path = "s3://${aws_s3_bucket.crawler_target.id}/data/"
    }]
  }

  schema_change_policy = {
    update_behavior = "LOG"
    delete_behavior = "LOG"
  }

  recrawl_policy = {
    recrawl_behavior = "CRAWL_NEW_FOLDERS_ONLY"
  }

  tags = jsonencode({
    "Modified By" = "AWSCC"
  })
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `role` (String) The Amazon Resource Name (ARN) of an IAM role that's used to access customer resources, such as Amazon Simple Storage Service (Amazon S3) data.
- `targets` (Attributes) Specifies data stores to crawl. (see [below for nested schema](#nestedatt--targets))

### Optional

- `classifiers` (List of String) A list of UTF-8 strings that specify the names of custom classifiers that are associated with the crawler.
- `configuration` (String) Crawler configuration information. This versioned JSON string allows users to specify aspects of a crawler's behavior.
- `crawler_security_configuration` (String) The name of the SecurityConfiguration structure to be used by this crawler.
- `database_name` (String) The name of the database in which the crawler's output is stored.
- `description` (String) A description of the crawler.
- `lake_formation_configuration` (Attributes) Specifies AWS Lake Formation configuration settings for the crawler (see [below for nested schema](#nestedatt--lake_formation_configuration))
- `name` (String) The name of the crawler.
- `recrawl_policy` (Attributes) When crawling an Amazon S3 data source after the first crawl is complete, specifies whether to crawl the entire dataset again or to crawl only folders that were added since the last crawler run. For more information, see Incremental Crawls in AWS Glue in the developer guide. (see [below for nested schema](#nestedatt--recrawl_policy))
- `schedule` (Attributes) A scheduling object using a cron statement to schedule an event. (see [below for nested schema](#nestedatt--schedule))
- `schema_change_policy` (Attributes) The policy that specifies update and delete behaviors for the crawler. The policy tells the crawler what to do in the event that it detects a change in a table that already exists in the customer's database at the time of the crawl. The SchemaChangePolicy does not affect whether or how new tables and partitions are added. New tables and partitions are always created regardless of the SchemaChangePolicy on a crawler. The SchemaChangePolicy consists of two components, UpdateBehavior and DeleteBehavior. (see [below for nested schema](#nestedatt--schema_change_policy))
- `table_prefix` (String) The prefix added to the names of tables that are created.
- `tags` (String) The tags to use with this crawler.

### Read-Only

- `id` (String) Uniquely identifies the resource.

<a id="nestedatt--targets"></a>
### Nested Schema for `targets`

Optional:

- `catalog_targets` (Attributes List) Specifies AWS Glue Data Catalog targets. (see [below for nested schema](#nestedatt--targets--catalog_targets))
- `delta_targets` (Attributes List) Specifies an array of Delta data store targets. (see [below for nested schema](#nestedatt--targets--delta_targets))
- `dynamo_db_targets` (Attributes List) Specifies Amazon DynamoDB targets. (see [below for nested schema](#nestedatt--targets--dynamo_db_targets))
- `hudi_targets` (Attributes List) Specifies Apache Hudi data store targets. (see [below for nested schema](#nestedatt--targets--hudi_targets))
- `iceberg_targets` (Attributes List) Specifies Apache Iceberg data store targets. (see [below for nested schema](#nestedatt--targets--iceberg_targets))
- `jdbc_targets` (Attributes List) Specifies JDBC targets. (see [below for nested schema](#nestedatt--targets--jdbc_targets))
- `mongo_db_targets` (Attributes List) A list of Mongo DB targets. (see [below for nested schema](#nestedatt--targets--mongo_db_targets))
- `s3_targets` (Attributes List) Specifies Amazon Simple Storage Service (Amazon S3) targets. (see [below for nested schema](#nestedatt--targets--s3_targets))

<a id="nestedatt--targets--catalog_targets"></a>
### Nested Schema for `targets.catalog_targets`

Optional:

- `connection_name` (String) The name of the connection for an Amazon S3-backed Data Catalog table to be a target of the crawl when using a Catalog connection type paired with a NETWORK Connection type.
- `database_name` (String) The name of the database to be synchronized.
- `dlq_event_queue_arn` (String) A valid Amazon dead-letter SQS ARN. For example, arn:aws:sqs:region:account:deadLetterQueue.
- `event_queue_arn` (String) A valid Amazon SQS ARN. For example, arn:aws:sqs:region:account:sqs.
- `tables` (List of String) A list of the tables to be synchronized.


<a id="nestedatt--targets--delta_targets"></a>
### Nested Schema for `targets.delta_targets`

Optional:

- `connection_name` (String) The name of the connection to use to connect to the Delta table target.
- `create_native_delta_table` (Boolean) Specifies whether the crawler will create native tables, to allow integration with query engines that support querying of the Delta transaction log directly.
- `delta_tables` (List of String)
- `write_manifest` (Boolean) Specifies whether to write the manifest files to the Delta table path.


<a id="nestedatt--targets--dynamo_db_targets"></a>
### Nested Schema for `targets.dynamo_db_targets`

Optional:

- `path` (String) The name of the DynamoDB table to crawl.
- `scan_all` (Boolean) Indicates whether to scan all the records, or to sample rows from the table. Scanning all the records can take a long time when the table is not a high throughput table. A value of true means to scan all records, while a value of false means to sample the records. If no value is specified, the value defaults to true.
- `scan_rate` (Number) The percentage of the configured read capacity units to use by the AWS Glue crawler. Read capacity units is a term defined by DynamoDB, and is a numeric value that acts as rate limiter for the number of reads that can be performed on that table per second.

The valid values are null or a value between 0.1 to 1.5. A null value is used when user does not provide a value, and defaults to 0.5 of the configured Read Capacity Unit (for provisioned tables), or 0.25 of the max configured Read Capacity Unit (for tables using on-demand mode).


<a id="nestedatt--targets--hudi_targets"></a>
### Nested Schema for `targets.hudi_targets`

Optional:

- `connection_name` (String) The name of the connection to use to connect to the Hudi target.
- `exclusions` (List of String) A list of global patterns used to exclude from the crawl.
- `maximum_traversal_depth` (Number) The maximum depth of Amazon S3 paths that the crawler can traverse to discover the Hudi metadata folder in your Amazon S3 path. Used to limit the crawler run time.
- `paths` (List of String) One or more Amazon S3 paths that contains Hudi metadata folders as s3://bucket/prefix .


<a id="nestedatt--targets--iceberg_targets"></a>
### Nested Schema for `targets.iceberg_targets`

Optional:

- `connection_name` (String) The name of the connection to use to connect to the Iceberg target.
- `exclusions` (List of String) A list of global patterns used to exclude from the crawl.
- `maximum_traversal_depth` (Number) The maximum depth of Amazon S3 paths that the crawler can traverse to discover the Iceberg metadata folder in your Amazon S3 path. Used to limit the crawler run time.
- `paths` (List of String) One or more Amazon S3 paths that contains Iceberg metadata folders as s3://bucket/prefix .


<a id="nestedatt--targets--jdbc_targets"></a>
### Nested Schema for `targets.jdbc_targets`

Optional:

- `connection_name` (String) The name of the connection to use to connect to the JDBC target.
- `enable_additional_metadata` (List of String) Specify a value of RAWTYPES or COMMENTS to enable additional metadata in table responses. RAWTYPES provides the native-level datatype. COMMENTS provides comments associated with a column or table in the database.

If you do not need additional metadata, keep the field empty.
- `exclusions` (List of String) A list of glob patterns used to exclude from the crawl. For more information, see Catalog Tables with a Crawler.
- `path` (String) The path of the JDBC target.


<a id="nestedatt--targets--mongo_db_targets"></a>
### Nested Schema for `targets.mongo_db_targets`

Optional:

- `connection_name` (String) The name of the connection to use to connect to the Amazon DocumentDB or MongoDB target.
- `path` (String) The path of the Amazon DocumentDB or MongoDB target (database/collection).


<a id="nestedatt--targets--s3_targets"></a>
### Nested Schema for `targets.s3_targets`

Optional:

- `connection_name` (String) The name of a connection which allows a job or crawler to access data in Amazon S3 within an Amazon Virtual Private Cloud environment (Amazon VPC).
- `dlq_event_queue_arn` (String) A valid Amazon dead-letter SQS ARN. For example, arn:aws:sqs:region:account:deadLetterQueue.
- `event_queue_arn` (String) A valid Amazon SQS ARN. For example, arn:aws:sqs:region:account:sqs.
- `exclusions` (List of String) A list of glob patterns used to exclude from the crawl.
- `path` (String) The path to the Amazon S3 target.
- `sample_size` (Number) Sets the number of files in each leaf folder to be crawled when crawling sample files in a dataset. If not set, all the files are crawled. A valid value is an integer between 1 and 249.



<a id="nestedatt--lake_formation_configuration"></a>
### Nested Schema for `lake_formation_configuration`

Optional:

- `account_id` (String) Required for cross account crawls. For same account crawls as the target data, this can be left as null.
- `use_lake_formation_credentials` (Boolean) Specifies whether to use AWS Lake Formation credentials for the crawler instead of the IAM role credentials.


<a id="nestedatt--recrawl_policy"></a>
### Nested Schema for `recrawl_policy`

Optional:

- `recrawl_behavior` (String) Specifies whether to crawl the entire dataset again or to crawl only folders that were added since the last crawler run. A value of CRAWL_EVERYTHING specifies crawling the entire dataset again. A value of CRAWL_NEW_FOLDERS_ONLY specifies crawling only folders that were added since the last crawler run. A value of CRAWL_EVENT_MODE specifies crawling only the changes identified by Amazon S3 events.


<a id="nestedatt--schedule"></a>
### Nested Schema for `schedule`

Optional:

- `schedule_expression` (String) A cron expression used to specify the schedule. For more information, see Time-Based Schedules for Jobs and Crawlers. For example, to run something every day at 12:15 UTC, specify cron(15 12 * * ? *).


<a id="nestedatt--schema_change_policy"></a>
### Nested Schema for `schema_change_policy`

Optional:

- `delete_behavior` (String) The deletion behavior when the crawler finds a deleted object. A value of LOG specifies that if a table or partition is found to no longer exist, do not delete it, only log that it was found to no longer exist. A value of DELETE_FROM_DATABASE specifies that if a table or partition is found to have been removed, delete it from the database. A value of DEPRECATE_IN_DATABASE specifies that if a table has been found to no longer exist, to add a property to the table that says 'DEPRECATED' and includes a timestamp with the time of deprecation.
- `update_behavior` (String) The update behavior when the crawler finds a changed schema. A value of LOG specifies that if a table or a partition already exists, and a change is detected, do not update it, only log that a change was detected. Add new tables and new partitions (including on existing tables). A value of UPDATE_IN_DATABASE specifies that if a table or partition already exists, and a change is detected, update it. Add new tables and partitions.

## Import

Import is supported using the following syntax:

In Terraform v1.12.0 and later, the [`import` block](https://developer.hashicorp.com/terraform/language/import) can be used with the `identity` attribute, for example:

```terraform
import {
  to = awscc_glue_crawler.example
  identity = {
    name = "name"
  }
}
```

<!-- schema generated by tfplugindocs -->
### Identity Schema

#### Required

- `name` (String) The name of the crawler

#### Optional

- `account_id` (String) AWS Account where this resource is managed
- `region` (String) Region where this resource is managed

In Terraform v1.5.0 and later, the [`import` block](https://developer.hashicorp.com/terraform/language/import) can be used with the `id` attribute, for example:

```terraform
import {
  to = awscc_glue_crawler.example
  id = "name"
}
```

The [`terraform import` command](https://developer.hashicorp.com/terraform/cli/commands/import) can be used, for example:

```shell
$ terraform import awscc_glue_crawler.example "name"
```
