
---
page_title: "awscc_glue_job Resource - terraform-provider-awscc"
subcategory: ""
description: |-
  Resource Type definition for AWS::Glue::Job
---

# awscc_glue_job (Resource)

Resource Type definition for AWS::Glue::Job

## Example Usage

### AWS Glue Python Job Configuration

Creates an AWS Glue Python shell job with version 3.0 running on Python 3.9, along with the necessary IAM role and permissions to access S3 and CloudWatch Logs.

~> This example is generated by LLM using Amazon Bedrock and validated using terraform validate, apply and destroy. While we strive for accuracy and quality, please note that the information provided may not be entirely error-free or up-to-date. We recommend independently verifying the content.

```terraform
# Data sources for AWS account ID and region
data "aws_caller_identity" "current" {}
# Note: Using data.aws_region.current.region (AWS provider v6.0+)
# For AWS provider < v6.0, use data.aws_region.current.name instead
data "aws_region" "current" {}

# IAM role policy document
data "aws_iam_policy_document" "trust" {
  statement {
    effect = "Allow"
    actions = [
      "sts:AssumeRole"
    ]
    principals {
      type = "Service"
      identifiers = [
        "glue.amazonaws.com"
      ]
    }
  }
}

# IAM role policy for Glue job
data "aws_iam_policy_document" "glue_job" {
  statement {
    effect = "Allow"
    actions = [
      "s3:GetObject",
      "s3:PutObject",
      "logs:CreateLogGroup",
      "logs:CreateLogStream",
      "logs:PutLogEvents"
    ]
    resources = [
      "arn:aws:s3:::aws-glue-*/*",
      "arn:aws:logs:${data.aws_region.current.region}:${data.aws_caller_identity.current.account_id}:log-group:/aws-glue/*"
    ]
  }
}

# IAM role for Glue job
resource "awscc_iam_role" "glue_job" {
  assume_role_policy_document = data.aws_iam_policy_document.trust.json
  path                        = "/service-role/"
  policies = [
    {
      policy_document = data.aws_iam_policy_document.glue_job.json
      policy_name     = "GlueJobPolicy"
    }
  ]
  role_name = "ExampleGlueJobRole"
  tags = [{
    key   = "Modified By"
    value = "AWSCC"
  }]
}

# Glue job
resource "awscc_glue_job" "example" {
  name        = "example-glue-job"
  description = "Example Glue Job created with AWSCC provider"
  role        = awscc_iam_role.glue_job.arn

  command = {
    name            = "pythonshell"
    python_version  = "3.9"
    script_location = "s3://aws-glue-scripts-${data.aws_caller_identity.current.account_id}-${data.aws_region.current.region}/example-script.py"
  }

  glue_version = "3.0"
  max_capacity = 0.0625

  execution_property = {
    max_concurrent_runs = 1
  }

  tags = [{
    key   = "Modified By"
    value = "AWSCC"
  }]
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `command` (Attributes) The code that executes a job. (see [below for nested schema](#nestedatt--command))
- `role` (String) The name or Amazon Resource Name (ARN) of the IAM role associated with this job.

### Optional

- `allocated_capacity` (Number) The number of capacity units that are allocated to this job.
- `connections` (Attributes) Specifies the connections used by a job (see [below for nested schema](#nestedatt--connections))
- `default_arguments` (String) The default arguments for this job, specified as name-value pairs.
- `description` (String) A description of the job.
- `execution_class` (String) Indicates whether the job is run with a standard or flexible execution class.
- `execution_property` (Attributes) The maximum number of concurrent runs that are allowed for this job. (see [below for nested schema](#nestedatt--execution_property))
- `glue_version` (String) Glue version determines the versions of Apache Spark and Python that AWS Glue supports.
- `job_mode` (String) Property description not available.
- `job_run_queuing_enabled` (Boolean) Property description not available.
- `log_uri` (String) This field is reserved for future use.
- `maintenance_window` (String) Property description not available.
- `max_capacity` (Number) The number of AWS Glue data processing units (DPUs) that can be allocated when this job runs.
- `max_retries` (Number) The maximum number of times to retry this job after a JobRun fails
- `name` (String) The name you assign to the job definition
- `non_overridable_arguments` (String) Non-overridable arguments for this job, specified as name-value pairs.
- `notification_property` (Attributes) Specifies configuration properties of a notification. (see [below for nested schema](#nestedatt--notification_property))
- `number_of_workers` (Number) The number of workers of a defined workerType that are allocated when a job runs.
- `security_configuration` (String) The name of the SecurityConfiguration structure to be used with this job.
- `tags` (String) The tags to use with this job.
- `timeout` (Number) The maximum time that a job run can consume resources before it is terminated and enters TIMEOUT status.
- `worker_type` (String) TThe type of predefined worker that is allocated when a job runs.

### Read-Only

- `id` (String) Uniquely identifies the resource.

<a id="nestedatt--command"></a>
### Nested Schema for `command`

Optional:

- `name` (String) The name of the job command
- `python_version` (String) The Python version being used to execute a Python shell job.
- `runtime` (String) Runtime is used to specify the versions of Ray, Python and additional libraries available in your environment
- `script_location` (String) Specifies the Amazon Simple Storage Service (Amazon S3) path to a script that executes a job


<a id="nestedatt--connections"></a>
### Nested Schema for `connections`

Optional:

- `connections` (List of String) A list of connections used by the job.


<a id="nestedatt--execution_property"></a>
### Nested Schema for `execution_property`

Optional:

- `max_concurrent_runs` (Number) The maximum number of concurrent runs allowed for the job.


<a id="nestedatt--notification_property"></a>
### Nested Schema for `notification_property`

Optional:

- `notify_delay_after` (Number) It is the number of minutes to wait before sending a job run delay notification after a job run starts

## Import

Import is supported using the following syntax:

```shell
$ terraform import awscc_glue_job.example "name"
```
